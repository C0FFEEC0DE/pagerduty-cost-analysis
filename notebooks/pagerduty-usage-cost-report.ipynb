{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# PagerDuty Usage Cost Report\n\nThis notebook analyzes PagerDuty alert usage and attributes product costs to services, teams, and escalation policies.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## CONFIG\n"
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      },
      "execution_count": null,
      "outputs": [],
      "source": "import json\nimport os\nimport time\nfrom datetime import datetime, date, timedelta\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple\n\nimport requests\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom dateutil.relativedelta import relativedelta\nfrom IPython.display import display, Markdown, clear_output\nimport ipywidgets as widgets\n\nPAGERDUTY_API_TOKEN = os.getenv(\"PAGERDUTY_API_TOKEN\")\nPAGERDUTY_API_BASE_URL = \"https://api.pagerduty.com\"\nMONTHLY_PAGERDUTY_COST_USD = 4200\nCACHE_DIR = Path(\".cache\")\nCACHE_TTL_HOURS = 24\n\nif not PAGERDUTY_API_TOKEN:\n    raise ValueError(\"Missing PAGERDUTY_API_TOKEN environment variable.\")\n\nCACHE_DIR.mkdir(parents=True, exist_ok=True)\n\n\ndef get_current_month_range() -> Tuple[date, date]:\n    today = date.today()\n    start = today.replace(day=1)\n    end = (start + relativedelta(months=1)) - timedelta(days=1)\n    return start, end\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## UI\n"
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "start_default, end_default = get_current_month_range()\n",
        "\n",
        "start_picker = widgets.DatePicker(\n",
        "    description=\"Start\",\n",
        "    value=start_default,\n",
        "    disabled=False,\n",
        ")\n",
        "end_picker = widgets.DatePicker(\n",
        "    description=\"End\",\n",
        "    value=end_default,\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "teams_select = widgets.SelectMultiple(\n",
        "    options=[\"All\"],\n",
        "    value=(\"All\",),\n",
        "    description=\"Teams\",\n",
        ")\n",
        "services_select = widgets.SelectMultiple(\n",
        "    options=[\"All\"],\n",
        "    value=(\"All\",),\n",
        "    description=\"Services\",\n",
        ")\n",
        "escalation_select = widgets.SelectMultiple(\n",
        "    options=[\"All\"],\n",
        "    value=(\"All\",),\n",
        "    description=\"Escalation Policies\",\n",
        ")\n",
        "\n",
        "\n",
        "top_n_dropdown = widgets.Dropdown(\n",
        "    options=[5, 10, 20, \"All\"],\n",
        "    value=10,\n",
        "    description=\"Top-N\",\n",
        ")\n",
        "\n",
        "run_button = widgets.Button(description=\"Run report\", button_style=\"primary\")\n",
        "\n",
        "progress_label = widgets.HTML(value=\"<b>Status:</b> Idle\")\n",
        "progress_bar = widgets.IntProgress(value=0, min=0, max=6, description=\"Progress\")\n",
        "progress_box = widgets.VBox([progress_label, progress_bar])\n",
        "\n",
        "ui_box = widgets.VBox([\n",
        "    widgets.HBox([start_picker, end_picker, top_n_dropdown]),\n",
        "    teams_select,\n",
        "    services_select,\n",
        "    escalation_select,\n",
        "    run_button,\n",
        "    progress_box,\n",
        "])\n",
        "\n",
        "log_output = widgets.Output()\n",
        "report_output = widgets.Output()\n",
        "executive_output = widgets.Output()\n",
        "\n",
        "\n",
        "def _display_ui():\n",
        "    display(ui_box)\n",
        "    display(log_output)\n",
        "    display(executive_output)\n",
        "    display(report_output)\n",
        "\n",
        "\n",
        "def _set_progress(step: int, message: str):\n",
        "    progress_bar.value = step\n",
        "    progress_label.value = f\"<b>Status:</b> {message}\"\n",
        "\n",
        "\n",
        "_display_ui()\n",
        "\n",
        "\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Token token={PAGERDUTY_API_TOKEN}\",\n",
        "    \"Accept\": \"application/vnd.pagerduty+json;version=2\",\n",
        "}\n",
        "\n",
        "\n",
        "def pd_get(endpoint: str, params: Dict) -> Dict:\n",
        "    url = f\"{PAGERDUTY_API_BASE_URL}{endpoint}\"\n",
        "    response = requests.get(url, headers=HEADERS, params=params, timeout=60)\n",
        "    if not response.ok:\n",
        "        snippet = response.text[:300]\n",
        "        raise RuntimeError(f\"PagerDuty API error {response.status_code}: {snippet}\")\n",
        "    return response.json()\n",
        "\n",
        "\n",
        "def fetch_paginated(endpoint: str, params: Dict, root_key: str) -> List[Dict]:\n",
        "    items = []\n",
        "    offset = 0\n",
        "    limit = 100\n",
        "    while True:\n",
        "        payload = params.copy()\n",
        "        payload.update({\"limit\": limit, \"offset\": offset})\n",
        "        data = pd_get(endpoint, payload)\n",
        "        batch = data.get(root_key, [])\n",
        "        items.extend(batch)\n",
        "        if not data.get(\"more\"):\n",
        "            break\n",
        "        offset += limit\n",
        "    return items\n",
        "\n",
        "\n",
        "def fetch_incidents(since: date, until: date) -> List[Dict]:\n",
        "    params = {\n",
        "        \"since\": since.isoformat(),\n",
        "        \"until\": until.isoformat(),\n",
        "        \"statuses[]\": [\"triggered\", \"acknowledged\", \"resolved\"],\n",
        "    }\n",
        "    return fetch_paginated(\"/incidents\", params, \"incidents\")\n",
        "\n",
        "\n",
        "def fetch_metadata() -> Dict[str, List[Dict]]:\n",
        "    services = fetch_paginated(\"/services\", {}, \"services\")\n",
        "    teams = fetch_paginated(\"/teams\", {}, \"teams\")\n",
        "    escalation_policies = fetch_paginated(\"/escalation_policies\", {}, \"escalation_policies\")\n",
        "    return {\n",
        "        \"services\": services,\n",
        "        \"teams\": teams,\n",
        "        \"escalation_policies\": escalation_policies,\n",
        "    }\n",
        "\n",
        "\n",
        "def normalize_incidents_to_df(incidents: List[Dict], metadata: Dict[str, List[Dict]]) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    service_lookup = {service.get(\"id\"): service for service in metadata.get(\"services\", [])}\n",
        "    for incident in incidents:\n",
        "        incident_id = incident.get(\"id\")\n",
        "        created_at = pd.to_datetime(incident.get(\"created_at\"))\n",
        "        service = incident.get(\"service\") or {}\n",
        "        escalation_policy = incident.get(\"escalation_policy\") or {}\n",
        "        teams = incident.get(\"teams\") or []\n",
        "        if not teams:\n",
        "            teams = service.get(\"teams\") or []\n",
        "        if not teams:\n",
        "            service_id = service.get(\"id\")\n",
        "            service_metadata = service_lookup.get(service_id, {}) if service_id else {}\n",
        "            teams = service_metadata.get(\"teams\") or []\n",
        "\n",
        "        if teams:\n",
        "            team_names = \", \".join([t.get(\"summary\", \"Unknown\") for t in teams]) or \"Unknown\"\n",
        "            team_ids = \", \".join([t.get(\"id\", \"\") for t in teams]) or \"Unknown\"\n",
        "        else:\n",
        "            team_names = \"Unknown\"\n",
        "            team_ids = \"Unknown\"\n",
        "\n",
        "        # PagerDuty alerts can be fetched per incident; using incident_id as incident-as-alert fallback.\n",
        "        alert_id = incident_id\n",
        "\n",
        "        rows.append({\n",
        "            \"alert_id\": alert_id,\n",
        "            \"incident_id\": incident_id,\n",
        "            \"created_at\": created_at,\n",
        "            \"day\": created_at.date() if pd.notnull(created_at) else None,\n",
        "            \"service_name\": service.get(\"summary\", \"Unknown\"),\n",
        "            \"service_id\": service.get(\"id\", \"Unknown\"),\n",
        "            \"team_name\": team_names,\n",
        "            \"team_id\": team_ids,\n",
        "            \"escalation_policy_name\": escalation_policy.get(\"summary\", \"Unknown\"),\n",
        "            \"escalation_policy_id\": escalation_policy.get(\"id\", \"Unknown\"),\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    return df\n",
        "\n",
        "def _cache_path(cache_key: str) -> Path:\n",
        "    safe_key = cache_key.replace(\"/\", \"_\")\n",
        "    return CACHE_DIR / f\"{safe_key}.json\"\n",
        "\n",
        "\n",
        "def _is_cache_fresh(path: Path, ttl_hours: int) -> bool:\n",
        "    if not path.exists():\n",
        "        return False\n",
        "    age_seconds = time.time() - path.stat().st_mtime\n",
        "    return age_seconds < ttl_hours * 3600\n",
        "\n",
        "\n",
        "def load_or_fetch_cache(cache_key: str, fetch_fn):\n",
        "    path = _cache_path(cache_key)\n",
        "    if _is_cache_fresh(path, CACHE_TTL_HOURS):\n",
        "        print(f\"Cache hit for {cache_key}. Using cached PagerDuty data.\")\n",
        "        return json.loads(path.read_text())\n",
        "\n",
        "    print(f\"Cache miss for {cache_key}. Fetching from API.\")\n",
        "    data = fetch_fn()\n",
        "    path.write_text(json.dumps(data))\n",
        "    return data\n",
        "\n",
        "\n",
        "def load_data(\n",
        "    since: date,\n",
        "    until: date,\n",
        "    progress_fn=None,\n",
        ") -> Tuple[pd.DataFrame, Dict[str, List[Dict]]]:\n",
        "    since_str = since.isoformat()\n",
        "    until_str = until.isoformat()\n",
        "\n",
        "    incidents_key = f\"incidents_{since_str}_{until_str}\"\n",
        "    metadata_key = f\"metadata_services_teams_policies_{since_str}_{until_str}\"\n",
        "\n",
        "    if progress_fn:\n",
        "        progress_fn(2, \"Loading incidents...\")\n",
        "    incidents = load_or_fetch_cache(incidents_key, lambda: fetch_incidents(since, until))\n",
        "\n",
        "    if progress_fn:\n",
        "        progress_fn(3, \"Loading services, teams, and escalation policies...\")\n",
        "    metadata = load_or_fetch_cache(metadata_key, fetch_metadata)\n",
        "\n",
        "    if progress_fn:\n",
        "        progress_fn(4, \"Normalizing incident data...\")\n",
        "    df = normalize_incidents_to_df(incidents, metadata)\n",
        "    return df, metadata\n",
        "\n",
        "def apply_filters(df: pd.DataFrame, teams, services, escalation_policies) -> pd.DataFrame:\n",
        "    filtered = df.copy()\n",
        "\n",
        "    if teams and \"All\" not in teams:\n",
        "        filtered = filtered[filtered[\"team_name\"].isin(teams)]\n",
        "    if services and \"All\" not in services:\n",
        "        filtered = filtered[filtered[\"service_name\"].isin(services)]\n",
        "    if escalation_policies and \"All\" not in escalation_policies:\n",
        "        filtered = filtered[filtered[\"escalation_policy_name\"].isin(escalation_policies)]\n",
        "\n",
        "    return filtered\n",
        "\n",
        "\n",
        "def compute_costs_and_aggregations(df: pd.DataFrame):\n",
        "    total_alerts = df[\"alert_id\"].nunique()\n",
        "    cost_per_alert = MONTHLY_PAGERDUTY_COST_USD / total_alerts if total_alerts else 0\n",
        "\n",
        "    def add_cost(grouped):\n",
        "        grouped = grouped.copy()\n",
        "        grouped[\"cost_usd\"] = grouped[\"alert_count\"] * cost_per_alert\n",
        "        return grouped\n",
        "\n",
        "    by_service = (\n",
        "        df.groupby([\"service_name\", \"service_id\"], dropna=False)[\"alert_id\"]\n",
        "        .nunique()\n",
        "        .reset_index(name=\"alert_count\")\n",
        "    )\n",
        "    by_service = add_cost(by_service)\n",
        "\n",
        "    by_team = (\n",
        "        df.groupby([\"team_name\", \"team_id\"], dropna=False)[\"alert_id\"]\n",
        "        .nunique()\n",
        "        .reset_index(name=\"alert_count\")\n",
        "    )\n",
        "    by_team = add_cost(by_team)\n",
        "\n",
        "    by_escalation = (\n",
        "        df.groupby([\"escalation_policy_name\", \"escalation_policy_id\"], dropna=False)[\"alert_id\"]\n",
        "        .nunique()\n",
        "        .reset_index(name=\"alert_count\")\n",
        "    )\n",
        "    by_escalation = add_cost(by_escalation)\n",
        "\n",
        "    alerts_over_time = (\n",
        "        df.groupby(\"day\")[\"alert_id\"]\n",
        "        .nunique()\n",
        "        .reset_index(name=\"alert_count\")\n",
        "        .sort_values(\"day\")\n",
        "    )\n",
        "\n",
        "    metrics = {\n",
        "        \"total_alerts\": total_alerts,\n",
        "        \"cost_per_alert\": cost_per_alert,\n",
        "    }\n",
        "\n",
        "    return metrics, by_service, by_team, by_escalation, alerts_over_time\n",
        "\n",
        "def render_charts_and_tables(by_service, by_team, by_escalation, alerts_over_time, top_n):\n",
        "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
        "\n",
        "    if top_n != \"All\":\n",
        "        top_services = by_service.sort_values(\"cost_usd\", ascending=False).head(int(top_n))\n",
        "    else:\n",
        "        top_services = by_service.sort_values(\"cost_usd\", ascending=False)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    ax.bar(top_services[\"service_name\"], top_services[\"cost_usd\"], color=\"#4C72B0\")\n",
        "    ax.set_title(\"Top Services by Attributed Cost\")\n",
        "    ax.set_xlabel(\"Service\")\n",
        "    ax.set_ylabel(\"Cost (USD)\")\n",
        "    ax.tick_params(axis=\"x\", rotation=45)\n",
        "    for label in ax.get_xticklabels():\n",
        "        label.set_ha(\"right\")\n",
        "    plt.tight_layout()\n",
        "    display(fig)\n",
        "    plt.close(fig)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    sorted_team = by_team.sort_values(\"cost_usd\", ascending=False)\n",
        "    ax.bar(sorted_team[\"team_name\"], sorted_team[\"cost_usd\"], color=\"#55A868\")\n",
        "    ax.set_title(\"Cost by Team\")\n",
        "    ax.set_xlabel(\"Team\")\n",
        "    ax.set_ylabel(\"Cost (USD)\")\n",
        "    ax.tick_params(axis=\"x\", rotation=45)\n",
        "    for label in ax.get_xticklabels():\n",
        "        label.set_ha(\"right\")\n",
        "    plt.tight_layout()\n",
        "    display(fig)\n",
        "    plt.close(fig)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    sorted_policy = by_escalation.sort_values(\"cost_usd\", ascending=False)\n",
        "    ax.bar(sorted_policy[\"escalation_policy_name\"], sorted_policy[\"cost_usd\"], color=\"#C44E52\")\n",
        "    ax.set_title(\"Cost by Escalation Policy\")\n",
        "    ax.set_xlabel(\"Escalation Policy\")\n",
        "    ax.set_ylabel(\"Cost (USD)\")\n",
        "    ax.tick_params(axis=\"x\", rotation=45)\n",
        "    for label in ax.get_xticklabels():\n",
        "        label.set_ha(\"right\")\n",
        "    plt.tight_layout()\n",
        "    display(fig)\n",
        "    plt.close(fig)\n",
        "\n",
        "    display(Markdown(\"### Alerts and Cost by Service\"))\n",
        "    display(by_service.sort_values(\"cost_usd\", ascending=False))\n",
        "\n",
        "    display(Markdown(\"### Alerts and Cost by Team\"))\n",
        "    display(by_team.sort_values(\"cost_usd\", ascending=False))\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 4))\n",
        "    ax.plot(alerts_over_time[\"day\"], alerts_over_time[\"alert_count\"], marker=\"o\")\n",
        "    ax.set_title(\"Alerts Over Time (Daily)\")\n",
        "    ax.set_xlabel(\"Day\")\n",
        "    ax.set_ylabel(\"Alert Count\")\n",
        "    ax.tick_params(axis=\"x\", rotation=45)\n",
        "    for label in ax.get_xticklabels():\n",
        "        label.set_ha(\"right\")\n",
        "    plt.tight_layout()\n",
        "    display(fig)\n",
        "    plt.close(fig)\n",
        "\n",
        "def render_executive_summary(metrics, by_service, by_team):\n",
        "    total_cost = by_service[\"cost_usd\"].sum()\n",
        "    total_alerts = metrics[\"total_alerts\"]\n",
        "    cost_per_alert = metrics[\"cost_per_alert\"]\n",
        "\n",
        "    top_services = by_service.sort_values(\"cost_usd\", ascending=False).head(3)\n",
        "    top_cost = top_services[\"cost_usd\"].sum()\n",
        "    cost_share = (top_cost / total_cost * 100) if total_cost else 0\n",
        "\n",
        "    top_teams = by_team.sort_values(\"cost_usd\", ascending=False).head(3)\n",
        "    team_names = \", \".join(top_teams[\"team_name\"].tolist()) if not top_teams.empty else \"None\"\n",
        "\n",
        "    lines = [\n",
        "        f\"Top 3 services account for {cost_share:.1f}% of total PagerDuty attributed cost.\",\n",
        "        f\"Total attributed PagerDuty cost for the selected period: ${total_cost:,.2f}.\",\n",
        "        f\"Total alerts in period: {total_alerts}; cost per alert: ${cost_per_alert:,.2f}.\",\n",
        "        f\"Top teams by attributed cost: {team_names}.\",\n",
        "    ]\n",
        "    return \"\\n\".join([f\"- {line}\" for line in lines])\n",
        "\n",
        "\n",
        "_cached_range = None\n",
        "_cached_df = None\n",
        "_cached_metadata = None\n",
        "\n",
        "\n",
        "def _reset_select_options(select_widget, options):\n",
        "    select_widget.value = (\"All\",)\n",
        "    select_widget.options = [\"All\"] + options\n",
        "\n",
        "\n",
        "def _update_filter_options(metadata, df):\n",
        "    services = sorted(set(df[\"service_name\"].dropna().tolist()))\n",
        "    teams = sorted(set(df[\"team_name\"].dropna().tolist()))\n",
        "    escalation_policies = sorted(set(df[\"escalation_policy_name\"].dropna().tolist()))\n",
        "\n",
        "    _reset_select_options(services_select, services)\n",
        "    _reset_select_options(teams_select, teams)\n",
        "    _reset_select_options(escalation_select, escalation_policies)\n",
        "\n",
        "\n",
        "def run_report(_=None):\n",
        "    global _cached_range, _cached_df, _cached_metadata\n",
        "\n",
        "    with log_output:\n",
        "        clear_output()\n",
        "        print(\"Starting report...\")\n",
        "    _set_progress(0, \"Starting report...\")\n",
        "\n",
        "    since = start_picker.value\n",
        "    until = end_picker.value\n",
        "    if since is None or until is None:\n",
        "        _set_progress(0, \"Missing start or end date.\")\n",
        "        raise ValueError(\"Both start and end dates are required.\")\n",
        "\n",
        "    _set_progress(1, \"Checking cache...\")\n",
        "\n",
        "    range_key = (since, until)\n",
        "    incidents_key = f\"incidents_{since.isoformat()}_{until.isoformat()}\"\n",
        "    metadata_key = f\"metadata_services_teams_policies_{since.isoformat()}_{until.isoformat()}\"\n",
        "    incidents_fresh = _is_cache_fresh(_cache_path(incidents_key), CACHE_TTL_HOURS)\n",
        "    metadata_fresh = _is_cache_fresh(_cache_path(metadata_key), CACHE_TTL_HOURS)\n",
        "\n",
        "    if _cached_range != range_key or not incidents_fresh or not metadata_fresh:\n",
        "        with log_output:\n",
        "            print(f\"Loading data for {since} to {until}...\")\n",
        "        try:\n",
        "            _cached_df, _cached_metadata = load_data(since, until, progress_fn=_set_progress)\n",
        "        except RuntimeError as exc:\n",
        "            with log_output:\n",
        "                print(f\"Report failed: {exc}\")\n",
        "            _set_progress(0, f\"Report failed: {exc}\")\n",
        "            return\n",
        "        _cached_range = range_key\n",
        "    else:\n",
        "        with log_output:\n",
        "            print(\"Using in-memory data for current date range.\")\n",
        "        _set_progress(4, \"Using cached data...\")\n",
        "\n",
        "    _update_filter_options(_cached_metadata, _cached_df)\n",
        "\n",
        "    filtered_df = apply_filters(\n",
        "        _cached_df,\n",
        "        teams_select.value,\n",
        "        services_select.value,\n",
        "        escalation_select.value,\n",
        "    )\n",
        "\n",
        "    _set_progress(5, \"Computing metrics...\")\n",
        "    metrics, by_service, by_team, by_escalation, alerts_over_time = compute_costs_and_aggregations(filtered_df)\n",
        "\n",
        "    with executive_output:\n",
        "        clear_output()\n",
        "        display(Markdown(\"### Executive Summary\"))\n",
        "        display(Markdown(render_executive_summary(metrics, by_service, by_team)))\n",
        "\n",
        "    with report_output:\n",
        "        clear_output()\n",
        "        render_charts_and_tables(by_service, by_team, by_escalation, alerts_over_time, top_n_dropdown.value)\n",
        "\n",
        "    _set_progress(6, \"Report complete.\")\n",
        "\n",
        "\n",
        "run_button.on_click(run_report)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## DATA\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## CACHE\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## CALC\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## VISUAL\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## EXECUTIVE\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}