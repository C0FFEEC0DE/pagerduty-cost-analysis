{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# PagerDuty Usage Cost Report\n\nThis notebook analyzes PagerDuty alert usage and attributes product costs to services, teams, and escalation policies.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## CONFIG\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import json\nimport os\nimport time\nfrom datetime import datetime, date, timedelta\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple\n\nimport requests\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom dateutil.relativedelta import relativedelta\nfrom IPython.display import display, Markdown, clear_output\nimport ipywidgets as widgets\n\nPAGERDUTY_API_TOKEN = os.getenv(\"PAGERDUTY_API_TOKEN\")\nPAGERDUTY_API_BASE_URL = \"https://api.pagerduty.com\"\nMONTHLY_PAGERDUTY_COST_USD = 4200\nCACHE_DIR = Path(\".cache\")\nCACHE_TTL_HOURS = 24\n\nif not PAGERDUTY_API_TOKEN:\n    raise ValueError(\"Missing PAGERDUTY_API_TOKEN environment variable.\")\n\nCACHE_DIR.mkdir(parents=True, exist_ok=True)\n\n\ndef get_current_month_range() -> Tuple[date, date]:\n    today = date.today()\n    start = today.replace(day=1)\n    end = (start + relativedelta(months=1)) - timedelta(days=1)\n    return start, end\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## UI\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "start_default, end_default = get_current_month_range()\n\nstart_picker = widgets.DatePicker(\n    description=\"Start\",\n    value=start_default,\n    disabled=False,\n)\nend_picker = widgets.DatePicker(\n    description=\"End\",\n    value=end_default,\n    disabled=False,\n)\n\nteams_select = widgets.SelectMultiple(\n    options=[\"All\"],\n    value=(\"All\",),\n    description=\"Teams\",\n)\nservices_select = widgets.SelectMultiple(\n    options=[\"All\"],\n    value=(\"All\",),\n    description=\"Services\",\n)\nescalation_select = widgets.SelectMultiple(\n    options=[\"All\"],\n    value=(\"All\",),\n    description=\"Escalation Policies\",\n)\n\n\ntop_n_dropdown = widgets.Dropdown(\n    options=[5, 10, 20, \"All\"],\n    value=10,\n    description=\"Top-N\",\n)\n\nrun_button = widgets.Button(description=\"Run report\", button_style=\"primary\")\n\nui_box = widgets.VBox([\n    widgets.HBox([start_picker, end_picker, top_n_dropdown]),\n    teams_select,\n    services_select,\n    escalation_select,\n    run_button,\n])\n\nlog_output = widgets.Output()\nreport_output = widgets.Output()\nexecutive_output = widgets.Output()\n\n\ndef _display_ui():\n    display(ui_box)\n    display(log_output)\n    display(executive_output)\n    display(report_output)\n\n_display_ui()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## DATA\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "HEADERS = {\n    \"Authorization\": f\"Token token={PAGERDUTY_API_TOKEN}\",\n    \"Accept\": \"application/vnd.pagerduty+json;version=2\",\n}\n\n\ndef pd_get(endpoint: str, params: Dict) -> Dict:\n    url = f\"{PAGERDUTY_API_BASE_URL}{endpoint}\"\n    response = requests.get(url, headers=HEADERS, params=params, timeout=60)\n    if not response.ok:\n        snippet = response.text[:300]\n        raise RuntimeError(f\"PagerDuty API error {response.status_code}: {snippet}\")\n    return response.json()\n\n\ndef fetch_paginated(endpoint: str, params: Dict, root_key: str) -> List[Dict]:\n    items = []\n    offset = 0\n    limit = 100\n    while True:\n        payload = params.copy()\n        payload.update({\"limit\": limit, \"offset\": offset})\n        data = pd_get(endpoint, payload)\n        batch = data.get(root_key, [])\n        items.extend(batch)\n        if not data.get(\"more\"):\n            break\n        offset += limit\n    return items\n\n\ndef fetch_incidents(since: date, until: date) -> List[Dict]:\n    params = {\n        \"since\": since.isoformat(),\n        \"until\": until.isoformat(),\n        \"statuses[]\": [\"triggered\", \"acknowledged\", \"resolved\"],\n    }\n    return fetch_paginated(\"/incidents\", params, \"incidents\")\n\n\ndef fetch_metadata() -> Dict[str, List[Dict]]:\n    services = fetch_paginated(\"/services\", {}, \"services\")\n    teams = fetch_paginated(\"/teams\", {}, \"teams\")\n    escalation_policies = fetch_paginated(\"/escalation_policies\", {}, \"escalation_policies\")\n    return {\n        \"services\": services,\n        \"teams\": teams,\n        \"escalation_policies\": escalation_policies,\n    }\n\n\ndef normalize_incidents_to_df(incidents: List[Dict]) -> pd.DataFrame:\n    rows = []\n    for incident in incidents:\n        incident_id = incident.get(\"id\")\n        created_at = pd.to_datetime(incident.get(\"created_at\"))\n        service = incident.get(\"service\") or {}\n        escalation_policy = incident.get(\"escalation_policy\") or {}\n        teams = incident.get(\"teams\") or []\n        team_names = \", \".join([t.get(\"summary\", \"Unknown\") for t in teams]) or \"Unknown\"\n        team_ids = \", \".join([t.get(\"id\", \"\") for t in teams]) or \"Unknown\"\n\n        # PagerDuty alerts can be fetched per incident; using incident_id as incident-as-alert fallback.\n        alert_id = incident_id\n\n        rows.append({\n            \"alert_id\": alert_id,\n            \"incident_id\": incident_id,\n            \"created_at\": created_at,\n            \"day\": created_at.date() if pd.notnull(created_at) else None,\n            \"service_name\": service.get(\"summary\", \"Unknown\"),\n            \"service_id\": service.get(\"id\", \"Unknown\"),\n            \"team_name\": team_names,\n            \"team_id\": team_ids,\n            \"escalation_policy_name\": escalation_policy.get(\"summary\", \"Unknown\"),\n            \"escalation_policy_id\": escalation_policy.get(\"id\", \"Unknown\"),\n        })\n\n    df = pd.DataFrame(rows)\n    return df\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## CACHE\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "def _cache_path(cache_key: str) -> Path:\n    safe_key = cache_key.replace(\"/\", \"_\")\n    return CACHE_DIR / f\"{safe_key}.json\"\n\n\ndef _is_cache_fresh(path: Path, ttl_hours: int) -> bool:\n    if not path.exists():\n        return False\n    age_seconds = time.time() - path.stat().st_mtime\n    return age_seconds < ttl_hours * 3600\n\n\ndef load_or_fetch_cache(cache_key: str, fetch_fn):\n    path = _cache_path(cache_key)\n    if _is_cache_fresh(path, CACHE_TTL_HOURS):\n        print(f\"Cache hit for {cache_key}. Using cached PagerDuty data.\")\n        return json.loads(path.read_text())\n\n    print(f\"Cache miss for {cache_key}. Fetching from API.\")\n    data = fetch_fn()\n    path.write_text(json.dumps(data))\n    return data\n\n\ndef load_data(since: date, until: date) -> Tuple[pd.DataFrame, Dict[str, List[Dict]]]:\n    since_str = since.isoformat()\n    until_str = until.isoformat()\n\n    incidents_key = f\"incidents_{since_str}_{until_str}\"\n    metadata_key = f\"metadata_services_teams_policies_{since_str}_{until_str}\"\n\n    incidents = load_or_fetch_cache(incidents_key, lambda: fetch_incidents(since, until))\n    metadata = load_or_fetch_cache(metadata_key, fetch_metadata)\n\n    df = normalize_incidents_to_df(incidents)\n    return df, metadata\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## CALC\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "def apply_filters(df: pd.DataFrame, teams, services, escalation_policies) -> pd.DataFrame:\n    filtered = df.copy()\n\n    if teams and \"All\" not in teams:\n        filtered = filtered[filtered[\"team_name\"].isin(teams)]\n    if services and \"All\" not in services:\n        filtered = filtered[filtered[\"service_name\"].isin(services)]\n    if escalation_policies and \"All\" not in escalation_policies:\n        filtered = filtered[filtered[\"escalation_policy_name\"].isin(escalation_policies)]\n\n    return filtered\n\n\ndef compute_costs_and_aggregations(df: pd.DataFrame):\n    total_alerts = df[\"alert_id\"].nunique()\n    cost_per_alert = MONTHLY_PAGERDUTY_COST_USD / total_alerts if total_alerts else 0\n\n    def add_cost(grouped):\n        grouped = grouped.copy()\n        grouped[\"cost_usd\"] = grouped[\"alert_count\"] * cost_per_alert\n        return grouped\n\n    by_service = (\n        df.groupby([\"service_name\", \"service_id\"], dropna=False)[\"alert_id\"]\n        .nunique()\n        .reset_index(name=\"alert_count\")\n    )\n    by_service = add_cost(by_service)\n\n    by_team = (\n        df.groupby([\"team_name\", \"team_id\"], dropna=False)[\"alert_id\"]\n        .nunique()\n        .reset_index(name=\"alert_count\")\n    )\n    by_team = add_cost(by_team)\n\n    by_escalation = (\n        df.groupby([\"escalation_policy_name\", \"escalation_policy_id\"], dropna=False)[\"alert_id\"]\n        .nunique()\n        .reset_index(name=\"alert_count\")\n    )\n    by_escalation = add_cost(by_escalation)\n\n    alerts_over_time = (\n        df.groupby(\"day\")[\"alert_id\"]\n        .nunique()\n        .reset_index(name=\"alert_count\")\n        .sort_values(\"day\")\n    )\n\n    metrics = {\n        \"total_alerts\": total_alerts,\n        \"cost_per_alert\": cost_per_alert,\n    }\n\n    return metrics, by_service, by_team, by_escalation, alerts_over_time\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## VISUAL\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "def render_charts_and_tables(by_service, by_team, by_escalation, alerts_over_time, top_n):\n    plt.style.use(\"seaborn-v0_8-whitegrid\")\n\n    if top_n != \"All\":\n        top_services = by_service.sort_values(\"cost_usd\", ascending=False).head(int(top_n))\n    else:\n        top_services = by_service.sort_values(\"cost_usd\", ascending=False)\n\n    fig, ax = plt.subplots(figsize=(10, 5))\n    ax.bar(top_services[\"service_name\"], top_services[\"cost_usd\"], color=\"#4C72B0\")\n    ax.set_title(\"Top Services by Attributed Cost\")\n    ax.set_xlabel(\"Service\")\n    ax.set_ylabel(\"Cost (USD)\")\n    ax.tick_params(axis=\"x\", rotation=45, ha=\"right\")\n    plt.tight_layout()\n    display(fig)\n    plt.close(fig)\n\n    fig, ax = plt.subplots(figsize=(10, 5))\n    sorted_team = by_team.sort_values(\"cost_usd\", ascending=False)\n    ax.bar(sorted_team[\"team_name\"], sorted_team[\"cost_usd\"], color=\"#55A868\")\n    ax.set_title(\"Cost by Team\")\n    ax.set_xlabel(\"Team\")\n    ax.set_ylabel(\"Cost (USD)\")\n    ax.tick_params(axis=\"x\", rotation=45, ha=\"right\")\n    plt.tight_layout()\n    display(fig)\n    plt.close(fig)\n\n    fig, ax = plt.subplots(figsize=(10, 5))\n    sorted_policy = by_escalation.sort_values(\"cost_usd\", ascending=False)\n    ax.bar(sorted_policy[\"escalation_policy_name\"], sorted_policy[\"cost_usd\"], color=\"#C44E52\")\n    ax.set_title(\"Cost by Escalation Policy\")\n    ax.set_xlabel(\"Escalation Policy\")\n    ax.set_ylabel(\"Cost (USD)\")\n    ax.tick_params(axis=\"x\", rotation=45, ha=\"right\")\n    plt.tight_layout()\n    display(fig)\n    plt.close(fig)\n\n    display(Markdown(\"### Alerts and Cost by Service\"))\n    display(by_service.sort_values(\"cost_usd\", ascending=False))\n\n    display(Markdown(\"### Alerts and Cost by Team\"))\n    display(by_team.sort_values(\"cost_usd\", ascending=False))\n\n    fig, ax = plt.subplots(figsize=(10, 4))\n    ax.plot(alerts_over_time[\"day\"], alerts_over_time[\"alert_count\"], marker=\"o\")\n    ax.set_title(\"Alerts Over Time (Daily)\")\n    ax.set_xlabel(\"Day\")\n    ax.set_ylabel(\"Alert Count\")\n    ax.tick_params(axis=\"x\", rotation=45, ha=\"right\")\n    plt.tight_layout()\n    display(fig)\n    plt.close(fig)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## EXECUTIVE\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def render_executive_summary(metrics, by_service, by_team):\n",
    "    total_cost = by_service[\"cost_usd\"].sum()\n",
    "    total_alerts = metrics[\"total_alerts\"]\n",
    "    cost_per_alert = metrics[\"cost_per_alert\"]\n",
    "\n",
    "    top_services = by_service.sort_values(\"cost_usd\", ascending=False).head(3)\n",
    "    top_cost = top_services[\"cost_usd\"].sum()\n",
    "    cost_share = (top_cost / total_cost * 100) if total_cost else 0\n",
    "\n",
    "    top_teams = by_team.sort_values(\"cost_usd\", ascending=False).head(3)\n",
    "    team_names = \", \".join(top_teams[\"team_name\"].tolist()) if not top_teams.empty else \"None\"\n",
    "\n",
    "    lines = [\n",
    "        f\"Top 3 services account for {cost_share:.1f}% of total PagerDuty attributed cost.\",\n",
    "        f\"Total attributed PagerDuty cost for the selected period: ${total_cost:,.2f}.\",\n",
    "        f\"Total alerts in period: {total_alerts}; cost per alert: ${cost_per_alert:,.2f}.\",\n",
    "        f\"Top teams by attributed cost: {team_names}.\",\n",
    "    ]\n",
    "    return \"\\n\".join([f\"- {line}\" for line in lines])\n",
    "\n",
    "\n",
    "_cached_range = None\n",
    "_cached_df = None\n",
    "_cached_metadata = None\n",
    "\n",
    "\n",
    "def _reset_select_options(select_widget, options):\n",
    "    select_widget.value = (\"All\",)\n",
    "    select_widget.options = [\"All\"] + options\n",
    "\n",
    "\n",
    "def _update_filter_options(metadata, df):\n",
    "    services = sorted(set(df[\"service_name\"].dropna().tolist()))\n",
    "    teams = sorted(set(df[\"team_name\"].dropna().tolist()))\n",
    "    escalation_policies = sorted(set(df[\"escalation_policy_name\"].dropna().tolist()))\n",
    "\n",
    "    _reset_select_options(services_select, services)\n",
    "    _reset_select_options(teams_select, teams)\n",
    "    _reset_select_options(escalation_select, escalation_policies)\n",
    "\n",
    "\n",
    "def run_report(_=None):\n",
    "    global _cached_range, _cached_df, _cached_metadata\n",
    "\n",
    "    with log_output:\n",
    "        clear_output()\n",
    "        print(\"Starting report...\")\n",
    "\n",
    "    since = start_picker.value\n",
    "    until = end_picker.value\n",
    "    if since is None or until is None:\n",
    "        raise ValueError(\"Both start and end dates are required.\")\n",
    "\n",
    "    range_key = (since, until)\n",
    "    incidents_key = f\"incidents_{since.isoformat()}_{until.isoformat()}\"\n",
    "    metadata_key = f\"metadata_services_teams_policies_{since.isoformat()}_{until.isoformat()}\"\n",
    "    incidents_fresh = _is_cache_fresh(_cache_path(incidents_key), CACHE_TTL_HOURS)\n",
    "    metadata_fresh = _is_cache_fresh(_cache_path(metadata_key), CACHE_TTL_HOURS)\n",
    "\n",
    "    if _cached_range != range_key or not incidents_fresh or not metadata_fresh:\n",
    "        with log_output:\n",
    "            print(f\"Loading data for {since} to {until}...\")\n",
    "        try:\n",
    "            _cached_df, _cached_metadata = load_data(since, until)\n",
    "        except RuntimeError as exc:\n",
    "            with log_output:\n",
    "                print(f\"Report failed: {exc}\")\n",
    "            return\n",
    "        _cached_range = range_key\n",
    "    else:\n",
    "        with log_output:\n",
    "            print(\"Using in-memory data for current date range.\")\n",
    "\n",
    "    _update_filter_options(_cached_metadata, _cached_df)\n",
    "\n",
    "    filtered_df = apply_filters(\n",
    "        _cached_df,\n",
    "        teams_select.value,\n",
    "        services_select.value,\n",
    "        escalation_select.value,\n",
    "    )\n",
    "\n",
    "    metrics, by_service, by_team, by_escalation, alerts_over_time = compute_costs_and_aggregations(filtered_df)\n",
    "\n",
    "    with executive_output:\n",
    "        clear_output()\n",
    "        display(Markdown(\"### Executive Summary\"))\n",
    "        display(Markdown(render_executive_summary(metrics, by_service, by_team)))\n",
    "\n",
    "    with report_output:\n",
    "        clear_output()\n",
    "        render_charts_and_tables(by_service, by_team, by_escalation, alerts_over_time, top_n_dropdown.value)\n",
    "\n",
    "\n",
    "run_button.on_click(run_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}